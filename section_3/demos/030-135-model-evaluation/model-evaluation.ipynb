{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Go through the process of evaluating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our transformations\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((128, 128)),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our Dataset Class and label encoding\n",
    "label_encoding = {\"malignant\": 0, \"benign\": 1}\n",
    "\n",
    "# Dataset Class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform, target_transform):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = lambda y: target_transform[y]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        image = self.transform(image)\n",
    "        label = self.target_transform(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Dataset\n",
    "test_dataset = CustomImageDataset(\n",
    "    annotations_file='test_data.csv', \n",
    "    img_dir=\"../../../\", \n",
    "    transform=test_transform, \n",
    "    target_transform=label_encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed modules\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Name the class\n",
    "class BreastCancerClassification(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(BreastCancerClassification, self).__init__()\n",
    "       # Create the layers\n",
    "       self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "       self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "       self.pool = nn.MaxPool2d(2, 2)\n",
    "      \n",
    "       self.fc1 = nn.Linear(64 * 32 * 32, 256)\n",
    "       self.fc2 = nn.Linear(256, 128)\n",
    "       self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "\n",
    "   def forward(self, x):\n",
    "       # Create the layer connections\n",
    "       x = self.pool(F.relu(self.conv1(x)))\n",
    "       x = self.pool(F.relu(self.conv2(x)))\n",
    "       x = x.view(-1, 64 * 32 * 32)\n",
    "       x = F.relu(self.fc1(x))\n",
    "       x = F.relu(self.fc2(x))\n",
    "       x = self.fc3(x)\n",
    "       return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of a model\n",
    "model = BreastCancerClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2_checkpoint.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load checkpoint\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2_checkpoint.tar\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lancaster\\Downloads\\PyTorch-main\\PyTorch-main\\pytorch_env\\Lib\\site-packages\\torch\\serialization.py:1479\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1477\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1480\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1481\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1482\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1483\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1484\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lancaster\\Downloads\\PyTorch-main\\PyTorch-main\\pytorch_env\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lancaster\\Downloads\\PyTorch-main\\PyTorch-main\\pytorch_env\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '2_checkpoint.tar'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('2_checkpoint.tar', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters to our model\n",
    "model.load_state_dict(checkpoint['model_state_dict']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time\n",
    "Single inputs for immediate response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = 'sample-input.jpg'\n",
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BreastCancerClassification(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=65536, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 83.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply the transformation\n",
    "transformed_image = test_transform(image)\n",
    "\n",
    "# Perform inference\n",
    "output = model(transformed_image)\n",
    "_, predicted = torch.max(output.data, 1) # Get the highest value from the raw scores\n",
    "\n",
    "# Print the class\n",
    "print(f\"Class: {predicted.item()}\") # item() gets the value out of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: benign\n"
     ]
    }
   ],
   "source": [
    "# Reverse index the label_encoding dictionary \n",
    "index_to_class_map = {v: k for k, v in label_encoding.items()}\n",
    "print(f\"Class: {index_to_class_map[predicted.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference\n",
    "Executing multiple inputs at a single time.\n",
    "\n",
    "What we will use in our training loop.\n",
    "\n",
    "A PyTorch DataLoader is done in batch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 32\n",
      "Dataset images: 100\n"
     ]
    }
   ],
   "source": [
    "# Show our test dataloader and dataset\n",
    "print(f\"batch size: {test_loader.batch_size}\")\n",
    "print(f\"Dataset images: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Class: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Class: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Class: tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Use the dataloader to perform batch inference\n",
    "for i, data in enumerate(test_loader, 0): # Loop over the whole dataloader in batches of 32\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # Perform inference as we did before\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f\"Class: {predicted}\") # notice we didn't use .item() here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.no_grad()\n",
    "Run the inference without gradients being calculated.\n",
    "\n",
    "Less resource intensive. Faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Class: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Class: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Class: tensor([0, 0, 0, 0])\n",
      "CPU times: total: 3.3 s\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Try again but time it\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f\"Class: {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Same but with no_grad()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        print(f\"Class: {predicted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchmetrics\n",
    "Torchmetrics is a handy tool that integrates very nicely into PyTorch to provide metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate torchmetrics \n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some inputs\n",
    "inputs = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],\n",
    "    [0.5, 2.5, 0.3],\n",
    "    [0.1, 0.4, 3.0],\n",
    "    [1.0, 0.8, 0.9],\n",
    "    [0.3, 1.5, 2.1],\n",
    "    [0.9, 2.1, 1.8],\n",
    "    [0.2, 3.0, 1.0],\n",
    "    [2.1, 0.1, 0.5],\n",
    "    [0.5, 2.5, 0.6],\n",
    "    [1.0, 0.5, 2.0] \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some true class labels. The first and the last are purposely incorrect.\n",
    "true_labels = torch.tensor([1, 1, 2, 0, 2, 1, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the accuracy metric for multi-class classification\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes) # Specifying multiple class task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate predictions on the inputs\n",
    "_, predicted = torch.max(inputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the metric with predictions and true labels\n",
    "accuracy.update(predicted, true_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# Compute the final accuracy\n",
    "final_accuracy = accuracy.compute()\n",
    "print(f\"Accuracy: {final_accuracy * 100}%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Loop\n",
    "Run model evaluation as part of a test loop and include Torchmetrics as our calculation framework\n",
    "\n",
    "For this we are going to include no_grad() and ensure our model is in evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.999996185302734%\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "# Initialize the accuracy metric\n",
    "accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)  # Adjust `num_classes` as needed\n",
    "\n",
    "# Test Loop with Torchmetrics\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    # Run test dataloader\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get predicted class\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update the accuracy metric with predictions and true labels\n",
    "        accuracy_metric.update(predicted, labels)\n",
    "\n",
    "# Compute the final accuracy\n",
    "final_accuracy = accuracy_metric.compute()\n",
    "print(f\"Accuracy: {final_accuracy * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We must reset the metric for future use or it will continue to update.\n",
    "accuracy_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metric Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize number of correct and total\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53%\n"
     ]
    }
   ],
   "source": [
    "# Optimized model evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
