{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Go through the process of evaluating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our transformations\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((128, 128)),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our Dataset Class and label encoding\n",
    "label_encoding = {\"malignant\": 0, \"benign\": 1}\n",
    "\n",
    "# Dataset Class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform, target_transform):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = lambda y: target_transform[y]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        image = self.transform(image)\n",
    "        label = self.target_transform(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Dataset\n",
    "test_dataset = CustomImageDataset(\n",
    "    annotations_file='test_data.csv', \n",
    "    img_dir=\"../../../\", \n",
    "    transform=test_transform, \n",
    "    target_transform=label_encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed modules\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Name the class\n",
    "class BreastCancerClassification(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(BreastCancerClassification, self).__init__()\n",
    "       # Create the layers\n",
    "       self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "       self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "       self.pool = nn.MaxPool2d(2, 2)\n",
    "      \n",
    "       self.fc1 = nn.Linear(64 * 32 * 32, 256)\n",
    "       self.fc2 = nn.Linear(256, 128)\n",
    "       self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "\n",
    "   def forward(self, x):\n",
    "       # Create the layer connections\n",
    "       x = self.pool(F.relu(self.conv1(x)))\n",
    "       x = self.pool(F.relu(self.conv2(x)))\n",
    "       x = x.view(-1, 64 * 32 * 32)\n",
    "       x = F.relu(self.fc1(x))\n",
    "       x = F.relu(self.fc2(x))\n",
    "       x = self.fc3(x)\n",
    "       return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of a model\n",
    "model = BreastCancerClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('2_checkpoint.tar', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters to our model\n",
    "model.load_state_dict(checkpoint['model_state_dict']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time\n",
    "Single inputs for immediate response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = 'sample-input.jpg'\n",
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply the transformation\n",
    "transformed_image = test_transform(image)\n",
    "\n",
    "# Perform inference\n",
    "output = model(transformed_image)\n",
    "_, predicted = torch.max(output.data, 1) # Get the highest value from the raw scores\n",
    "\n",
    "# Print the class\n",
    "print(f\"Class: {predicted.item()}\") # item() gets the value out of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse index the label_encoding dictionary \n",
    "index_to_class_map = {v: k for k, v in label_encoding.items()}\n",
    "print(f\"Class: {index_to_class_map[predicted.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference\n",
    "Executing multiple inputs at a single time.\n",
    "\n",
    "What we will use in our training loop.\n",
    "\n",
    "A PyTorch DataLoader is done in batch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our test dataloader and dataset\n",
    "print(f\"batch size: {test_loader.batch_size}\")\n",
    "print(f\"Dataset images: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataloader to perform batch inference\n",
    "for i, data in enumerate(test_loader, 0): # Loop over the whole dataloader in batches of 32\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # Perform inference as we did before\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f\"Class: {predicted}\") # notice we didn't use .item() here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.no_grad()\n",
    "Run the inference without gradients being calculated.\n",
    "\n",
    "Less resource intensive. Faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Try again but time it\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f\"Class: {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Same but with no_grad()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        print(f\"Class: {predicted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchmetrics\n",
    "Torchmetrics is a handy tool that integrates very nicely into PyTorch to provide metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate torchmetrics \n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some inputs\n",
    "inputs = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],\n",
    "    [0.5, 2.5, 0.3],\n",
    "    [0.1, 0.4, 3.0],\n",
    "    [1.0, 0.8, 0.9],\n",
    "    [0.3, 1.5, 2.1],\n",
    "    [0.9, 2.1, 1.8],\n",
    "    [0.2, 3.0, 1.0],\n",
    "    [2.1, 0.1, 0.5],\n",
    "    [0.5, 2.5, 0.6],\n",
    "    [1.0, 0.5, 2.0] \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some true class labels. The first and the last are purposely incorrect.\n",
    "true_labels = torch.tensor([1, 1, 2, 0, 2, 1, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the accuracy metric for multi-class classification\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes) # Specifying multiple class task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate predictions on the inputs\n",
    "_, predicted = torch.max(inputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the metric with predictions and true labels\n",
    "accuracy.update(predicted, true_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the final accuracy\n",
    "final_accuracy = accuracy.compute()\n",
    "print(f\"Accuracy: {final_accuracy * 100}%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Loop\n",
    "Run model evaluation as part of a test loop and include Torchmetrics as our calculation framework\n",
    "\n",
    "For this we are going to include no_grad() and ensure our model is in evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "# Initialize the accuracy metric\n",
    "accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)  # Adjust `num_classes` as needed\n",
    "\n",
    "# Test Loop with Torchmetrics\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    # Run test dataloader\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get predicted class\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update the accuracy metric with predictions and true labels\n",
    "        accuracy_metric.update(predicted, labels)\n",
    "\n",
    "# Compute the final accuracy\n",
    "final_accuracy = accuracy_metric.compute()\n",
    "print(f\"Accuracy: {final_accuracy * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We must reset the metric for future use or it will continue to update.\n",
    "accuracy_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metric Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize number of correct and total\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update total count with labels\n",
    "        total += labels.size(0)\n",
    "        # If predicted is the same as correct update the number\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# To get accuracy percentage multiply 100 by the correct number and divide by total\n",
    "print(f'Accuracy: {100 * correct // total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
