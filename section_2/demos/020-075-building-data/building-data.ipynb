{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Data\n",
    "In this demo we are going to go through the process of building a custom dataset to use to train our model.\n",
    "\n",
    "This is an example process of building data to use for model training.\n",
    "\n",
    "We will cover some new concepts and best practices as well as review some concepts we have learned over the last few lessons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and preprocessing\n",
    "Data cleaning and preprocessing help make sure that only clear, useful images are used to train the model, which leads to better accuracy. These steps remove any messy or confusing data so the model can learn patterns more easily.\n",
    "\n",
    "This is no right or wrong way to do this but it is important to examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all images in our dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Get a list of images with jpg\n",
    "images_list = glob.glob(\"images/*/*jpg\")\n",
    "\n",
    "# Open each image\n",
    "for image in images_list:\n",
    "    # Set the title\n",
    "    plt.title(image)\n",
    "    # Open the image\n",
    "    img = Image.open(image)\n",
    "    plt.axis(\"on\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print our image list\n",
    "print(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove images from our list that we dont want\n",
    "images_list.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using an annotations file lets write the final list to a csv with its class\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_path in images_list:\n",
    "    # Extract the class label from the path ie: dog or cat\n",
    "    label = os.path.basename(os.path.dirname(file_path))\n",
    "    # Append path and label \n",
    "    data.append({\"file_path\": file_path, \"label\": label})\n",
    "\n",
    "# Save DF as CSV file\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"image_data.csv\", index=False)\n",
    "\n",
    "# Here we created our intitial annotations file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an initial PyTorch Dataset\n",
    "Once our data is cleaned up and ready, we need to create an initial Dataset that consists of all eligible images.\n",
    "\n",
    "This is so we can split our data into Training, Validation and Testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InitialDataset(Dataset):\n",
    "    def __init__(self, annotations_file):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        return img_path, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch Dataset\n",
    "dataset = InitialDataset(annotations_file='image_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the annoations\n",
    "dataset.img_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Split\n",
    "Review:\n",
    "\n",
    "The `random_split` function in PyTorch helps divide your dataset into different parts such as training, validation and testin sets, by randomly selecting samples for each part. \n",
    "\n",
    "This is important because splitting data lets you train the model on one part and test it on another, helping you see how well the model performs on new, unseen data. \n",
    "\n",
    "Randomly splitting the data ensures each set has a good mix, making the model’s evaluation more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splits:\n",
    "\n",
    "**Training data** is the largest portion, and it’s what the model learns from by finding patterns in the data. \n",
    "\n",
    "**Validation data** is used during training to tune the model’s settings, helping prevent overfitting so the model doesn’t just memorize the training data. \n",
    "\n",
    "**Testing data** is used after training to check how well the model performs on completely new data. This setup ensures the model can make accurate predictions on data it hasn’t seen before, making it more useful and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random_split from PyTorch's data utilities\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of Training data from the full dataset 70%\n",
    "train_size = int(0.7 * len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of Validation data from the full dataset 15%\n",
    "val_size = int(0.15 * len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally define the rest as test data 15%\n",
    "test_size = len(dataset) - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training, validation and testing dataset by splitting the full dataset by size\n",
    "# Here we use random_split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the outputs we get from the subsets\n",
    "print(train_dataset.indices, val_dataset.indices, test_dataset.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `random_split` PyTorch is a list of Subset objects, each representing a portion of the original dataset.\n",
    "\n",
    "We can use these lists of indexes to retrieve samples from our original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the original dataset to our index\n",
    "# Print the annotations\n",
    "dataset.img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the item in the dataset at the first index of the train_dataset\n",
    "dataset.img_labels.loc[train_dataset.indices[0]]\n",
    "# We can do the same for other indexes and for validation datasets and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Versioning and Tracking\n",
    "As we covered in the video, there are multiple ways to version your data and we wont cover any particular method in this course.\n",
    "\n",
    "However, the reason we are covering this is because it is a best practice.\n",
    "\n",
    "Versioning and tracking makes your work more reliable and allows you to reproduce results consistently, even if the data changes over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets write annotation files for each of our subsets of data. \n",
    "# This method can be used for other forms of model training outside of images such as text, audio, etc\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "# For each index in the training indices \n",
    "for idx in train_dataset.indices:\n",
    "    # Extract the file_path and the label from the original dataset \n",
    "    img_path = dataset.img_labels['file_path'].loc[idx]\n",
    "    label = dataset.img_labels['label'].loc[idx]\n",
    "    # Append path and label \n",
    "    data.append({\"file_path\": img_path, \"label\": label})\n",
    "\n",
    "# Save DF as CSV file\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing for our validation and testing sets.\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "# For each index in the validation indices \n",
    "for idx in val_dataset.indices:\n",
    "    # Extract the file_path and the label from the original dataset \n",
    "    img_path = dataset.img_labels['file_path'].loc[idx]\n",
    "    label = dataset.img_labels['label'].loc[idx]\n",
    "    # Append path and label \n",
    "    data.append({\"file_path\": img_path, \"label\": label})\n",
    "\n",
    "# Save DF as CSV file\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"validation_data.csv\", index=False)\n",
    "\n",
    "# For each index in the test indices \n",
    "for idx in test_dataset.indices:\n",
    "    # Extract the file_path and the label from the original dataset \n",
    "    img_path = dataset.img_labels['file_path'].loc[idx]\n",
    "    label = dataset.img_labels['label'].loc[idx]\n",
    "    # Append path and label \n",
    "    data.append({\"file_path\": img_path, \"label\": label})\n",
    "\n",
    "# Save DF as CSV file\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"testing_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Transformations\n",
    "Lets go ahead and define transformations for our subsets of data. \n",
    "\n",
    "Remember that there is a possibility that training could have different transforms than validation. This is present a more diverse sample to the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by import transforms\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Pipeline\n",
    "import torch\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    v2.Resize((128, 128)), # Resize the image\n",
    "    v2.RandomCrop(size=(75, 75)), # Random Crop\n",
    "    v2.RandomHorizontalFlip(p=.7), # Randomly flip horizontally\n",
    "    # Convert to tensor\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Pipeline\n",
    "val_transform = v2.Compose([\n",
    "    v2.Resize((128, 128)), # Resize to a fixed size\n",
    "    # Convert to tensor\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Datasets and DataLoaders\n",
    "Now that we have subsets of our data and individual transformations, we can create PyTorch Datasets from our subsets of data and DataLoaders for those subsets to load them into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets begin by defining our Custom Dataset \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform, target_transform):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = lambda y: target_transform[y]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        # Transform the image\n",
    "        image = self.transform(image)\n",
    "        # Get the label\n",
    "        label = self.target_transform(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the label encoding\n",
    "label_encoding = {\"cat\": 0, \"dog\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset \n",
    "train_dataset = CustomImageDataset(\n",
    "    annotations_file='training_data.csv', \n",
    "    img_dir=\"./\", \n",
    "    transform=train_transform, \n",
    "    target_transform=label_encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the training data\n",
    "train_dataset.img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label encoding\n",
    "train_dataset.target_transform('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "train_dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation dataset\n",
    "val_dataset = CustomImageDataset(\n",
    "    annotations_file='validation_data.csv', \n",
    "    img_dir=\"./\", \n",
    "    transform=val_transform, \n",
    "    target_transform=label_encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the transforms\n",
    "val_dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoaders for each PyTorch Dataset\n",
    "# Import DataLoader\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through and print the batch size\n",
    "features, labels = next(iter(train_loader))\n",
    "print(f\"Features shape: {features.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Validation DataLoader NOTICE the False shuffle\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate \n",
    "features, labels = next(iter(val_loader))\n",
    "print(f\"Features shape: {features.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You are now ready to begin training a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
