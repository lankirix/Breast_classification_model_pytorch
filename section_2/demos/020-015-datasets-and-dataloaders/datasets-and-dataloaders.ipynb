{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Datasets and DataLoaders\n",
    "This demo covers PyTorch Datasets and DataLoaders. We will pickup and cover the topics from the video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# PyTorch Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Pre-loaded Datasets\n",
    "Let's begin by covering \"pre-loaded\" Datasets in PyTorch\n",
    "\n",
    "These are perfect for beginning working with Datasets or for research/experimentation.\n",
    "\n",
    "Pre-loaded Datasets available: Image, Text and Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's begin with Pre-loaded Audio files\n",
    "# Import torchaudio \n",
    "import torchaudio.datasets\n",
    "\n",
    "# To get a list of available Audio Datasets go to Documentation URL: https://pytorch.org/audio/stable/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset using DR_VCTK (Device Recorded VCTK https://pytorch.org/audio/stable/references.html#id42)\n",
    "audio_dataset = torchaudio.datasets.DR_VCTK(root='./audio', subset='test', download=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a pre-loaded image dataset\n",
    "# Import the torchvision datasets library\n",
    "import torchvision.datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from the FashionMNIST classification dataset \n",
    "image_dataset = torchvision.datasets.FashionMNIST(root='./fashion', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# NOTE: Ignore the transform for now. Tensors are required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the Classes of a dataset \n",
    "print(image_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classes to their indexes \n",
    "print(image_dataset.class_to_idx)\n",
    "\n",
    "# This is an attribute used to map class names to integer values because models require integer values for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the class to index mapping for plotting\n",
    "class_to_index_map = image_dataset.class_to_idx\n",
    "index_to_class_map = {v: k for k, v in class_to_index_map.items()}\n",
    "print(index_to_class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a visual of our dataset with 9 random images\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set up our plot\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(image_dataset), size=(1,)).item()\n",
    "    img, label = image_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(index_to_class_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch DataLoaders\n",
    "Now that we have a working dataset, lets begin defining how we are going to present or load our data to our model.\n",
    "\n",
    "This is done using DataLoaders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataLoader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataloader from our image_dataset above\n",
    "image_dataloader = DataLoader(dataset=image_dataset, batch_size=64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader Parameters review\n",
    "batch_size: Number of samples (images) are loaded at a time.\n",
    "\n",
    "shuffle: When True, images are randomized before sending to the model.\n",
    "\n",
    "num_workers: Number of processes to use for loading data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the image_dataloader\n",
    "features, labels = next(iter(image_dataloader))\n",
    "# Print the batch size and the number of labels\n",
    "print(f\"Features shape: {features.size()}\")\n",
    "print(f\"Labels shape: {labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image with its label from a random image in our batch\n",
    "import random\n",
    "\n",
    "# Get a random value between 0 and our batch size\n",
    "rand_indx = random.randint(0, labels.size()[0])\n",
    "\n",
    "# set image and label\n",
    "img = features[rand_indx].squeeze()\n",
    "label = labels[rand_indx]\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# Print its label and map its numeric value to the actual name of its class\n",
    "print(f\"Label: {label} -> {index_to_class_map[label.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "So far we have created Datasets using PyTorch's pre-loaded datasets.\n",
    "\n",
    "We have also created a DataLoader used to define our to present our dataset to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Datasets\n",
    "Lets take a look at how to create custom datasets in Pytorch using our own existing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Define our Dataset Class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, class_list):\n",
    "        self.df = pd.read_csv(annotations_file)\n",
    "        self.class_list = class_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.df.file_path[index])\n",
    "        img_url = self.df.file_path[index]\n",
    "        # Images must be tensors. Ignore transformations for now.\n",
    "        convert_tensor = transforms.ToTensor()\n",
    "        image = convert_tensor(image)\n",
    "        label = self.class_list.index(self.df.label[index])\n",
    "\n",
    "        return image, label, img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset Class Review\n",
    "\n",
    "__init__ method: Peforms initial setup and load the data. \n",
    "\n",
    "__len__ method: Returns the number of samples for batch.\n",
    "\n",
    "__getitem__ method: Retrieves a single data sample based on an index.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create our custom dataset!\n",
    "# We must define an annotations file and a list of classes\n",
    "class_list = [\"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset\n",
    "custom_dataset = CustomImageDataset(annotations_file='labels.csv', class_list=class_list)\n",
    "print(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print attributes of our dataset (__init__ method)\n",
    "\n",
    "# Display our annotations\n",
    "print(f\"Annotations data: \\n{custom_dataset.df}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our classes\n",
    "print(f\"Classes: {custom_dataset.class_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our class to index map\n",
    "print(f\"Mapped Classes: {custom_dataset.class_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own mapper OR we could add this in our __getitem__ method\n",
    "custom_class_labels_map = {0: 'cat', 1: 'dog'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a visual of our dataset with 9 random images\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Set up our plot\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(custom_dataset), size=(1,)).item()\n",
    "    img, label = custom_dataset[sample_idx][2], custom_dataset[sample_idx][1]\n",
    "    img = Image.open(img)\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for our custom dataset\n",
    "custom_dataloader = DataLoader(dataset=custom_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through this dataloader like we did above\n",
    "features, labels, urls = next(iter(custom_dataloader))\n",
    "# Print the batch size and the number of labels\n",
    "print(f\"Features shape: {features.size()}\")\n",
    "print(f\"Labels shape: {labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image with its label from a random image in our batch\n",
    "import random\n",
    "\n",
    "# Get a random value between 0 and our batch size\n",
    "rand_indx = random.randint(0, labels.size()[0])\n",
    "\n",
    "# set image and label\n",
    "img = urls[rand_indx]\n",
    "label = labels[rand_indx]\n",
    "\n",
    "# Plot the image\n",
    "img = Image.open(img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# Print its label and map its numeric value to the actual name of its class\n",
    "print(f\"Label: {label} -> {custom_class_labels_map.get(label.item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision ImageFolder\n",
    "Create a dataset using the folder structure as a way to label your images.\n",
    "\n",
    "This utility simplifies the process of loading datasets where images are organized in a directory structure.\n",
    "\n",
    "Example:\n",
    "```bash\n",
    "images/\n",
    "    ├── cat/\n",
    "    │   ├── cat1.jpg\n",
    "    │   ├── cat2.jpg\n",
    "    ├── dog/\n",
    "    │   ├── dog1.jpg\n",
    "    │   └── dog2.jpg\n",
    "```\n",
    "\n",
    "Each image will be labled by its directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torchvision\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset using ImageFolder \n",
    "image_folder_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"images\", # images directory\n",
    "    transform=transforms.Compose([transforms.ToTensor()])) # Ignore this for now\n",
    "print(image_folder_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the Classes of a dataset \n",
    "print(image_folder_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classes to their indexes \n",
    "print(image_folder_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into dataloader\n",
    "image_folder_dataloader = DataLoader(image_folder_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve one batch of images and labels\n",
    "images, labels = next(iter(image_folder_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the batch above\n",
    "fig, axes = plt.subplots(1, len(images), figsize=(8, 8))\n",
    "\n",
    "for i, (img, label) in enumerate(zip(images, labels)):\n",
    "    img = img.permute(1, 2, 0) # Ignore this\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(image_folder_dataset.classes[label])\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
