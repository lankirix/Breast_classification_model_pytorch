{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment on Kubernetes\n",
    "In this demo we are going to look at different ways to run Model Deployments on Kubernetes.\n",
    "\n",
    "For HPA example (metric server install):\n",
    "https://github.com/kubernetes-sigs/metrics-server/issues/196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having a Look around\n",
    "In the `manifests` directory.\n",
    "\n",
    "```bash\n",
    "manifests\n",
    "├── deployment.yaml\n",
    "├── hpa.yaml\n",
    "├── service.yaml\n",
    "```\n",
    "\n",
    "Deploy it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal Pod Autoscaler\n",
    "HPA plays a huge role in being able to handle scaling your applications up and down.\n",
    "\n",
    "This is especially useful for ML/AI workloads.\n",
    "\n",
    "```yaml\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: ml-model-hpa\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: ml-model-deployment\n",
    "  minReplicas: 3\n",
    "  maxReplicas: 10\n",
    "  metrics:\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: cpu\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 70\n",
    "```\n",
    "\n",
    "`scaleTargetRef` defines what we are going to target to scale.\n",
    "\n",
    "`minReplicas` and `maxRelicas` define the minimum and maximum number of pods to be running high or light load.\n",
    "\n",
    "`metrics` is where we define the target resource to watch in order to trigger scaling events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Affinity\n",
    "Node affinity ensures that pods are scheduled on specific nodes by matching labels on the nodes with rules defined in the pod's configuration. \n",
    "\n",
    "It provides control over where workloads run, enabling optimization for hardware or specialized requirements, such as scheduling ML workloads on GPU-enabled nodes.\n",
    "\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: ml-model-deployment\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: ml-model\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: ml-model\n",
    "    spec:\n",
    "      affinity:\n",
    "        nodeAffinity:\n",
    "          requiredDuringSchedulingIgnoredDuringExecution:\n",
    "            nodeSelectorTerms:\n",
    "            - matchExpressions:\n",
    "              - key: kubernetes.io/hostname\n",
    "                operator: In\n",
    "                values:\n",
    "                - \"node02\"\n",
    "      containers:\n",
    "      - name: ml-model-container\n",
    "        image: wbassler/mobilenetv3lg-flask:v1.0\n",
    "        imagePullPolicy: Always\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "          limits:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Selector\n",
    "Another way to schedule pods to specific nodes is through the use of `nodeSelector`. \n",
    "\n",
    "`nodeSelector` is not a flexible and is a simple key value match whereas node affinity is more advanced and flexible due to rules requirements. \n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: ml-model-deployment\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: ml-model\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: ml-model\n",
    "    spec:\n",
    "      nodeSelector:\n",
    "        kubernetes.io/hostname: \"node02\"\n",
    "      containers:\n",
    "      - name: ml-model-container\n",
    "        image: wbassler/mobilenetv3lg-flask:v1.0\n",
    "        imagePullPolicy: Always\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "          limits:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taints\n",
    "Taints prevent pods from being scheduled on specific nodes unless the pods explicitly tolerate the taint. \n",
    "\n",
    "They are used to reserve nodes for specialized workloads or to isolate certain nodes.\n",
    "\n",
    "```bash\n",
    "kubectl taint nodes node02 role=pytorch:NoSchedule\n",
    "```\n",
    "\n",
    "```bash\n",
    "kubectl describe node node02 | grep Taints\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tolerations\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: ml-model-deployment\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: ml-model\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: ml-model\n",
    "    spec:\n",
    "      tolerations:\n",
    "      - key: \"role\"\n",
    "        operator: \"Equal\"\n",
    "        value: \"pytorch\"\n",
    "        effect: \"NoSchedule\"\n",
    "      nodeSelector:\n",
    "        kubernetes.io/hostname: \"node02\"\n",
    "      containers:\n",
    "      - name: ml-model-container\n",
    "        image: wbassler/mobilenetv3lg-flask:v1.0\n",
    "        imagePullPolicy: Always\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "          limits:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning GPUs\n",
    "Using GPU enabled nodes requires a couple additional things configured on your nodes. \n",
    "\n",
    "For NVIDIA:\n",
    "\n",
    "1) Cluster has GPU-enabled nodes and that the NVIDIA drivers are installed on those nodes.\n",
    "\n",
    "2) NVIDIA device plugin installed. More information [https://github.com/NVIDIA/k8s-device-plugin](https://github.com/NVIDIA/k8s-device-plugin).\n",
    "\n",
    "3) Update your deployment with below:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: ml-model-deployment\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: ml-model\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: ml-model\n",
    "    spec:\n",
    "      tolerations:\n",
    "      - key: \"role\"\n",
    "        operator: \"Equal\"\n",
    "        value: \"pytorch\"\n",
    "        effect: \"NoSchedule\"\n",
    "      nodeSelector:\n",
    "        kubernetes.io/hostname: \"node02\"\n",
    "      containers:\n",
    "      - name: ml-model-container\n",
    "        image: wbassler/mobilenetv3lg-flask:v1.0\n",
    "        imagePullPolicy: Always\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "            nvidia.com/gpu: 1    # Request 1 GPU\n",
    "          limits:\n",
    "            cpu: \"200m\"\n",
    "            memory: \"250Mi\"\n",
    "            nvidia.com/gpu: 1    # Request 1 GPU\n",
    "```\n",
    "\n",
    "NOTE: Ensure that your application is configured to leverage GPU acceleration. ie: NVIDIA drivers and libraries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
